{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can now model strong lenses. We can balance complexity and realism to ensure that we infer a good lens model. And\n",
    "# we can do this to make the analysis run faster. However, we always need to be wary of run-time. If we don't craft\n",
    "# our phases carefully, we could spend days, or longer, modeling just one image. In this exercise, we'll get thinking\n",
    "# about what determines the length of time an AutoLens analysis takes, and how one might speed it up.\n",
    "\n",
    "### Searching Non-linear Parameter Space ###\n",
    "\n",
    "# We've covered this already. The more complex your parameter space (e.g. the more parameters), the longer it takes to\n",
    "# search. The broader your priors, the longer it takes to search. The slower you search non-linear parameter space,\n",
    "# the longer PyAutoLens takes to run.\n",
    "\n",
    "# There isn't much else to say here - just that, once we start thinking about pipeline's, we'll start linking phases\n",
    "# together in ways that navigate non-linear parameter spaces in an extremely efficient manner.\n",
    "\n",
    "### Algorithmic Optimization ###\n",
    "\n",
    "# Every operation AutoLens performs to fit a lens takes time. Every light profile intensity. Every mass profile\n",
    "# deflection angle. Convolving a model-image with a PSF can take a huge amount of time. As anyone who's written code\n",
    "# before knows, the better the algorithm is written, the fast it'll run.\n",
    "\n",
    "# I often get asked, given that PyAutoLens is written in Python, isn't it really slow? Afterall, Python is notoriously\n",
    "# slow. Well, no, it isn't. We use a library called 'Numba', that allows us to recompile our Python functions into \n",
    "# C functions before PyAutoLens runs. This gives us C-like speed, but in Python code. If you've got your own code that \n",
    "# needs speeding up, I strongly recommend that you look up Numba:\n",
    "\n",
    "# http://numba.pydata.org/\n",
    "\n",
    "# We've worked very hard to profile every line of code in AutoLens and we're confident its as fast, if not faster,\n",
    "# than any code written in C. In fact, we know this - I wrote the original version of AutoLens in Fortran (bless my\n",
    "# soul) and we timed it against PyAutoLens. After invoking the magic of Numba, PyAutoLens ran 3 times faster than the\n",
    "# Fortran code - I felt pretty smug at that point.\n",
    "\n",
    "# We probably arn't going to see much more of speed-up via optimization then. Of course, if you'd like to prove me\n",
    "# wrong, go for it - I'll buy you a beer at a conference someday if you do.\n",
    "\n",
    "### Data Quantity ###\n",
    "\n",
    "# The final factor driving run-speed is the shear quantity of data that we're modeling. For every image-pixel that we\n",
    "# fit, we have to compute the light-profile intensities, the mass-profile deflection angles and convolve it with\n",
    "# the telescope's PSF. The larger that PSF is, the more convolution operations we have to perform too.\n",
    "\n",
    "# In the previous exercises, we used images with a pixel scale of 0.1\". I sneakily chose this value cause its fairly\n",
    "# low resolution. Most Hubble images have a pixel scale of 0.05\", which is four times the number of pixels! Some \n",
    "# telescopes observe at scales of 0.03\" or, dare I say it, 0.01\", at these resolutions we things will run really slow, \n",
    "# if we don't think carefully about run speed beforehand.\n",
    "\n",
    "# Of course, there are ways that we can reduce the number of image-pixels we fit. That's what masking does. If we mask \n",
    "# out more of the image, we'll fit fewer pixels and AutoLens will run faster. Alternatively, we could 'bin-up' the \n",
    "# image, converting it from say a 0.03\" image to a 0.06\" image. We lose information, but the code runs\n",
    "# faster. We could trim our PSF to a smaller size, at the risk of modeling our telescope optics worse. \n",
    "\n",
    "# If you want the best, most perfect lens model possible, aggressively masking and cutting the data in this way is a \n",
    "# bad idea. However, if your analysis is composed of multiple phases, and in the early phases you just want a \n",
    "# reasonable lens model which fits the data reasonably well, why bother fitting all the image data? \n",
    "# You can do that in the last phase, right?\n",
    "\n",
    "# Herein lies the beauty behind pipelines. Not only can we tune their navigation of non-linear parameter space, we can \n",
    "# freely butcher our data to keep AutoLens running fast. Yeah, the last phase might take a while to run, because\n",
    "# we're fitting a larger quantity of data, but at this point we've tuned our lens model priors so much the phase can't\n",
    "# take too long.\n",
    "\n",
    "# Therefore, there are n o exercises in this tutorial and no code to run. We're going to hold off thinking about \n",
    "# run-speed until we introduce pipelines. Instead, I just want you to think about how you might write a pipeline to \n",
    "# perform the following analyses:\n",
    "\n",
    "# 1) The only thing you care about is the highly magnified source-galaxy. You don't care about the lens galaxy's\n",
    "#    light profile, and its mass-profile is only a means to ultimately study the unlensed source. Can you subtract\n",
    "#    the lens galaxy's light and then discard it in every phase afterwards?\n",
    "\n",
    "# 2) There are 2 lens galaxies responsible for lensing the background source. That means, there are twice as many\n",
    "#    lens galaxy parameters. Can you setup phases that fit each galaxy individiually, before fitting them jointly?\n",
    "\n",
    "#  3) The source galaxy is really complex. Infact, in your strong lens image you count 12 distinct multiple images,\n",
    "#     meaning that there are at least three distinct source's of light in the source plane. This is a potentially \n",
    "#     very complex non-linear parameter space, so how might you break down the analysis?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
